{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract XML to JSON (documents > sections > subsections) w/ links\n",
    "\n",
    "This notebook cleans up, combines and improves on the code of the previous 2 notebooks.\n",
    "\n",
    "It produces a large JSON file which is used in the following notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import lxml.etree as ET\n",
    "import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.dirname(current_dir)\n",
    "laws_dir = os.path.join(root_dir, \"laws-lois-xml\")\n",
    "xsl_filename = os.path.join(laws_dir, \"xslt\", \"LIMS2HTML.xsl\")\n",
    "\n",
    "en_acts = [\n",
    "    os.path.join(os.path.join(laws_dir, \"eng\", \"acts\"), f)\n",
    "    for f in os.listdir(os.path.join(laws_dir, \"eng\", \"acts\"))\n",
    "    if f.endswith(\".xml\")\n",
    "]\n",
    "en_regs = [\n",
    "    os.path.join(os.path.join(laws_dir, \"eng\", \"regulations\"), f)\n",
    "    for f in os.listdir(os.path.join(laws_dir, \"eng\", \"regulations\"))\n",
    "    if f.endswith(\".xml\")\n",
    "]\n",
    "fr_acts = [\n",
    "    os.path.join(os.path.join(laws_dir, \"fra\", \"lois\"), f)\n",
    "    for f in os.listdir(os.path.join(laws_dir, \"fra\", \"lois\"))\n",
    "    if f.endswith(\".xml\")\n",
    "]\n",
    "fr_regs = [\n",
    "    os.path.join(os.path.join(laws_dir, \"fra\", \"reglements\"), f)\n",
    "    for f in os.listdir(os.path.join(laws_dir, \"fra\", \"reglements\"))\n",
    "    if f.endswith(\".xml\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_text(element):\n",
    "    return element.text if element is not None else None\n",
    "\n",
    "\n",
    "def _get_link(element):\n",
    "    return (\n",
    "        element.attrib[\"link\"]\n",
    "        if element is not None and \"link\" in element.attrib.keys()\n",
    "        else None\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_joined_text(element_list, exclude_tags=[\"MarginalNote\"]):\n",
    "    return (\n",
    "        \"\\n\".join(\n",
    "            [t.text for t in element_list if t.tag not in exclude_tags and t.text]\n",
    "        )\n",
    "        if element_list\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dict_from_xml(xml_filename, extract_full_text=False):\n",
    "    # Extract a JSON serializable dictionary from a act/regulation XML file\n",
    "    dom = ET.parse(xml_filename)\n",
    "    root = dom.getroot()\n",
    "    d = {\n",
    "        \"id\": os.path.basename(xml_filename).replace(\".xml\", \"\"),\n",
    "        \"lang\": os.path.basename(os.path.dirname(os.path.dirname(xml_filename))),\n",
    "        \"type\": \"act\" if root.tag == \"Statute\" else \"regulation\",\n",
    "        \"short_title\": _get_text(root.find(\".//ShortTitle\")),\n",
    "        \"long_title\": _get_text(root.find(\".//LongTitle\")),\n",
    "        \"bill_number\": _get_text(root.find(\".//BillNumber\")),\n",
    "        \"instrument_number\": _get_text(root.find(\".//InstrumentNumber\")),\n",
    "        \"consolidated_number\": _get_text(root.find(\".//ConsolidatedNumber\")),\n",
    "        \"last_amended_date\": root.attrib.get(\n",
    "            \"{http://justice.gc.ca/lims}lastAmendedDate\", None\n",
    "        ),\n",
    "        \"current_date\": root.attrib.get(\n",
    "            \"{http://justice.gc.ca/lims}current-date\", None\n",
    "        ),\n",
    "        \"in_force_start_date\": root.attrib.get(\n",
    "            \"{http://justice.gc.ca/lims}inforce-start-date\", None\n",
    "        ),\n",
    "        \"enabling_authority\": {\n",
    "            \"link\": _get_link(root.find(\".//EnablingAuthority/XRefExternal\")),\n",
    "            \"text\": _get_text(root.find(\".//EnablingAuthority/XRefExternal\")),\n",
    "        },\n",
    "        \"sections\": get_preamble(root)\n",
    "        + [get_section(section) for section in root.findall(\".//Section\")],\n",
    "    }\n",
    "    # Aggregate all internal and external references and count instances of each\n",
    "    for ref_name in [\"internal_refs\", \"external_refs\"]:\n",
    "        ref_list = [\n",
    "            ref\n",
    "            for section in d[\"sections\"]\n",
    "            for ref in section[ref_name]\n",
    "            if ref[\"link\"] is not None\n",
    "        ]\n",
    "        ref_list_set = set([ref[\"link\"] for ref in ref_list])\n",
    "        d[ref_name] = [\n",
    "            {\n",
    "                \"link\": link,\n",
    "                \"count\": len([ref for ref in ref_list if ref[\"link\"] == link]),\n",
    "            }\n",
    "            for link in ref_list_set\n",
    "        ]\n",
    "    if extract_full_text:\n",
    "        # Sometimes the XML will not parse correctly so we need to catch the error\n",
    "        try:\n",
    "            d[\"full_text\"] = xml_to_markdown(xml_filename)\n",
    "        except:\n",
    "            d[\"full_text\"] = _get_joined_text(root.findall(\".//*\"))\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_section(section):\n",
    "    return {\n",
    "        \"id\": str(section.find(\"Label\").text),\n",
    "        \"text\": _get_joined_text(section.findall(\".//*\")),\n",
    "        \"marginal_note\": _get_text(section.find(\"MarginalNote\")),\n",
    "        \"lims_id\": section.attrib.get(\"{http://justice.gc.ca/lims}id\", None),\n",
    "        \"subsections\": [\n",
    "            get_section(subsection) for subsection in section.findall(\".//Subsection\")\n",
    "        ]\n",
    "        if section.tag == \"Section\"\n",
    "        else [],\n",
    "        \"headings\": get_headings(section) if section.tag == \"Section\" else [],\n",
    "        \"external_refs\": get_external_xrefs(section),\n",
    "        \"internal_refs\": get_internal_xrefs(section),\n",
    "        # \"xml\": ET.tostring(section, encoding=\"unicode\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_headings(section):\n",
    "    # Headings are sibling elements which may precede Sections\n",
    "    headings = []\n",
    "    prev_elem = section.getprevious()\n",
    "    # Loop while the previous element is a Heading\n",
    "    while prev_elem is not None and prev_elem.tag == \"Heading\":\n",
    "        headings.append(\n",
    "            {\n",
    "                \"level\": prev_elem.get(\"level\"),\n",
    "                \"text\": _get_joined_text(prev_elem.findall(\".//*\")),\n",
    "            }\n",
    "        )\n",
    "        # Continue with the previous sibling\n",
    "        prev_elem = prev_elem.getprevious()\n",
    "    return headings\n",
    "\n",
    "\n",
    "def get_external_xrefs(section):\n",
    "    # External references have an explicit link attribute\n",
    "    return [\n",
    "        {\n",
    "            \"link\": xref.attrib.get(\"link\", None),\n",
    "            \"reference_type\": xref.attrib.get(\"reference-type\", None),\n",
    "            \"text\": xref.text,\n",
    "        }\n",
    "        for xref in section.findall(\".//XRefExternal\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_internal_xrefs(section):\n",
    "    # Internal references are always a section number which is the text\n",
    "    return [\n",
    "        {\n",
    "            \"link\": xref.text,\n",
    "        }\n",
    "        for xref in section.findall(\".//XRefInternal\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_preamble(root):\n",
    "    # Returns an array with a single element, the preamble, or no elements\n",
    "    # so that it can be easily prepended to the sections array\n",
    "    preamble = root.find(\".//Preamble\")\n",
    "    if preamble is None:\n",
    "        return []\n",
    "    preamble.findall(\".//Provision\")\n",
    "    return [\n",
    "        {\n",
    "            \"id\": \"0\",\n",
    "            \"text\": _get_joined_text(preamble.findall(\".//*\")),\n",
    "            \"subsections\": [\n",
    "                {\n",
    "                    \"id\": i,\n",
    "                    \"text\": _get_joined_text(provision.findall(\".//*\")),\n",
    "                }\n",
    "                for i, provision in enumerate(preamble.findall(\".//Provision\"))\n",
    "            ],\n",
    "            \"internal_refs\": get_internal_xrefs(preamble),\n",
    "            \"external_refs\": get_external_xrefs(preamble),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "def xslt_transform(xml_filename, xsl_filename):\n",
    "    # https://stackoverflow.com/questions/16698935/how-to-transform-an-xml-file-using-xslt-in-python\n",
    "    dom = ET.parse(xml_filename)\n",
    "    xslt = ET.parse(xsl_filename)\n",
    "    transform = ET.XSLT(xslt)\n",
    "    newdom = transform(dom)\n",
    "    return ET.tostring(newdom, pretty_print=True)\n",
    "\n",
    "\n",
    "def xml_to_markdown(xml_filename, xsl_filename=xsl_filename, remove_links=True):\n",
    "    html = xslt_transform(xml_filename, xsl_filename)\n",
    "    html = html.decode(\"utf-8\")\n",
    "    # To correct an issue where words are concatenated...\n",
    "    html = html.replace(\"</span>\", \"</span> \")\n",
    "    markdown = md(html)\n",
    "\n",
    "    # Now remove multiple spaces and > 2 newlines\n",
    "    # There should be at most 1 space in a row\n",
    "    markdown = re.sub(\" +\", \" \", markdown)\n",
    "    markdown = re.sub(\"\\n{2,}\", \"\\n\\n\", markdown)\n",
    "\n",
    "    if remove_links:\n",
    "        # Replace links with the link text only\n",
    "        markdown = re.sub(r\"\\[(.*?)\\]\\(.*?\\)\", r\"\\1\", markdown)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11136/11136 [00:19<00:00, 563.85it/s] \n"
     ]
    }
   ],
   "source": [
    "all_xml = en_acts + en_regs + fr_acts + fr_regs\n",
    "\n",
    "\n",
    "def extract_xml_no_fulltext(filename):\n",
    "    return get_dict_from_xml(filename, extract_full_text=False)\n",
    "\n",
    "\n",
    "legislation = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_xml_no_fulltext)(filename) for filename in tqdm.tqdm(all_xml)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 537,021 KB\n",
    "\n",
    "# with open(os.path.join(current_dir, \"legislation.json\"), \"w\") as f:\n",
    "#     json.dump(legislation, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11136/11136 [05:10<00:00, 35.83it/s] \n"
     ]
    }
   ],
   "source": [
    "def extract_xml_with_fulltext(filename):\n",
    "    return get_dict_from_xml(filename, extract_full_text=True)\n",
    "\n",
    "\n",
    "legislation_full = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_xml_with_fulltext)(filename) for filename in tqdm.tqdm(all_xml)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 859,755 KB\n",
    "\n",
    "with open(os.path.join(current_dir, \"legislation_fulltext.json\"), \"w\") as f:\n",
    "    json.dump(legislation_full, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
